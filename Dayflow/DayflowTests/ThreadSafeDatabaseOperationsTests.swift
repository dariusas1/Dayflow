//
//  ThreadSafeDatabaseOperationsTests.swift
//  DayflowTests
//
//  Created by Development Agent on 2025-11-14.
//  Story 1.3: Thread-Safe Database Operations
//
//  Comprehensive test suite validating all 6 acceptance criteria:
//  - AC-1.3.1: DatabaseManager handles all GRDB operations
//  - AC-1.3.2: No priority inversion errors during background AI processing
//  - AC-1.3.3: UI remains responsive during background database operations
//  - AC-1.3.4: All database operations complete without threading errors
//  - AC-1.3.5: Database transactions properly isolated
//  - AC-1.3.6: Database operation latency <100ms P95
//

import XCTest
@testable import Dayflow
import GRDB

final class ThreadSafeDatabaseOperationsTests: XCTestCase {

    var storage: StorageManager!
    var dbManager: DatabaseManager!

    override func setUpWithError() throws {
        try super.setUpWithError()
        storage = StorageManager.shared
        dbManager = DatabaseManager.shared
    }

    override func tearDownWithError() throws {
        try super.tearDownWithError()
    }

    // MARK: - AC-1.3.1: DatabaseManager Handles All GRDB Operations

    func testRegisterChunkUsesDatabaseManager() async throws {
        // Verify that registerChunk uses DatabaseManager async pattern
        let testURL = URL(fileURLWithPath: "/tmp/test-chunk-\(UUID().uuidString).mp4")

        try await storage.registerChunk(url: testURL)

        // Verify chunk was registered
        let chunks = try await storage.fetchUnprocessedChunks(olderThan: 0)
        XCTAssertTrue(chunks.contains(where: { $0.fileUrl == testURL.path }), "Chunk should be registered in database")
    }

    func testMarkChunkCompletedUsesDatabaseManager() async throws {
        // Setup: Register a chunk first
        let testURL = URL(fileURLWithPath: "/tmp/test-chunk-\(UUID().uuidString).mp4")
        try await storage.registerChunk(url: testURL)

        // Test: Mark it completed
        try await storage.markChunkCompleted(url: testURL)

        // Verify: Check status is 'completed'
        let chunks = try await storage.fetchUnprocessedChunks(olderThan: 0)
        let chunk = chunks.first(where: { $0.fileUrl == testURL.path })
        XCTAssertEqual(chunk?.status, "completed", "Chunk status should be 'completed'")
    }

    func testSaveBatchUsesDatabaseManager() async throws {
        // Test saveBatch uses DatabaseManager and transaction
        let startTs = Int(Date().timeIntervalSince1970)
        let endTs = startTs + 900

        // Register some test chunks
        let chunk1URL = URL(fileURLWithPath: "/tmp/chunk1-\(UUID().uuidString).mp4")
        let chunk2URL = URL(fileURLWithPath: "/tmp/chunk2-\(UUID().uuidString).mp4")
        try await storage.registerChunk(url: chunk1URL)
        try await storage.registerChunk(url: chunk2URL)
        try await storage.markChunkCompleted(url: chunk1URL)
        try await storage.markChunkCompleted(url: chunk2URL)

        let chunks = try await storage.fetchUnprocessedChunks(olderThan: 0)
        let chunkIds = chunks.filter { $0.fileUrl == chunk1URL.path || $0.fileUrl == chunk2URL.path }.map { $0.id }

        // Create batch
        let batchId = try await storage.saveBatch(startTs: startTs, endTs: endTs, chunkIds: chunkIds)

        XCTAssertNotNil(batchId, "Batch ID should be created")

        // Verify transaction atomicity - both chunks should be associated with batch
        if let batchId = batchId {
            let batchChunks = try await storage.chunksForBatch(batchId)
            XCTAssertEqual(batchChunks.count, chunkIds.count, "All chunks should be associated with batch atomically")
        }
    }

    func testFetchBatchLLMMetadataUsesDatabaseManager() async throws {
        // Setup: Create a batch
        let startTs = Int(Date().timeIntervalSince1970)
        let endTs = startTs + 900

        let batchId = try await storage.saveBatch(startTs: startTs, endTs: endTs, chunkIds: [])
        XCTAssertNotNil(batchId)

        guard let batchId = batchId else { return }

        // Add LLM metadata
        let testCalls = [
            LLMCall(timestamp: Date(), latency: 1.5, input: "test input", output: "test output")
        ]
        try await storage.updateBatchLLMMetadata(batchId: batchId, calls: testCalls)

        // Test: Fetch metadata
        let fetched = try await storage.fetchBatchLLMMetadata(batchId: batchId)

        XCTAssertEqual(fetched.count, testCalls.count, "Should fetch correct number of LLM calls")
    }

    // MARK: - AC-1.3.2 & AC-1.3.4: Concurrent Access Without Crashes

    func testConcurrentDatabaseOperationsNoCrashes() async throws {
        // Simulate concurrent database operations from multiple threads
        let iterations = 20

        await withTaskGroup(of: Void.self) { group in
            // Concurrent writes
            for i in 0..<iterations {
                group.addTask {
                    let url = URL(fileURLWithPath: "/tmp/concurrent-chunk-\(i).mp4")
                    try? await self.storage.registerChunk(url: url)
                }
            }

            // Concurrent reads
            for _ in 0..<iterations {
                group.addTask {
                    _ = try? await self.storage.fetchUnprocessedChunks(olderThan: 0)
                }
            }

            // Wait for all tasks
            await group.waitForAll()
        }

        // If we got here without crashes, test passes
        XCTAssert(true, "Concurrent operations completed without crashes")
    }

    func testConcurrentBatchCreationNoCrashes() async throws {
        // Test concurrent batch creation with transaction isolation
        let startTs = Int(Date().timeIntervalSince1970)

        var batchIds: [Int64] = []

        await withTaskGroup(of: Int64?.self) { group in
            for i in 0..<10 {
                group.addTask {
                    return try? await self.storage.saveBatch(
                        startTs: startTs + (i * 1000),
                        endTs: startTs + (i * 1000) + 900,
                        chunkIds: []
                    )
                }
            }

            for await batchId in group {
                if let batchId = batchId {
                    batchIds.append(batchId)
                }
            }
        }

        XCTAssertGreaterThan(batchIds.count, 0, "Should create batches concurrently without crashes")
        XCTAssertEqual(Set(batchIds).count, batchIds.count, "All batch IDs should be unique (proper transaction isolation)")
    }

    // MARK: - AC-1.3.5: Transaction Isolation

    func testTransactionAtomicity() async throws {
        // Test that batch creation is atomic - all chunks are added or none
        let startTs = Int(Date().timeIntervalSince1970)
        let endTs = startTs + 900

        // This test simulates a transaction that should be atomic
        let chunkIds: [Int64] = [999999, 999998] // Non-existent IDs

        do {
            _ = try await storage.saveBatch(startTs: startTs, endTs: endTs, chunkIds: chunkIds)
            XCTFail("Should throw error for non-existent chunks")
        } catch {
            // Expected behavior - transaction should roll back
            // Verify no partial batch was created
            let batches = try await storage.allBatches()
            let recentBatch = batches.first(where: { $0.start == startTs })
            XCTAssertNil(recentBatch, "No partial batch should exist after transaction rollback")
        }
    }

    func testTransactionRollbackOnMidTransactionFailure() async throws {
        // Test transaction rollback when failure occurs mid-way through multi-step operation
        // This tests a more realistic scenario where some operations succeed before failure

        // Setup: Create valid chunks
        let chunk1URL = URL(fileURLWithPath: "/tmp/rollback-chunk1-\(UUID().uuidString).mp4")
        let chunk2URL = URL(fileURLWithPath: "/tmp/rollback-chunk2-\(UUID().uuidString).mp4")

        try await storage.registerChunk(url: chunk1URL)
        try await storage.registerChunk(url: chunk2URL)
        try await storage.markChunkCompleted(url: chunk1URL)
        try await storage.markChunkCompleted(url: chunk2URL)

        let chunks = try await storage.fetchUnprocessedChunks(olderThan: 0)
        let validChunkIds = chunks.filter { $0.fileUrl == chunk1URL.path || $0.fileUrl == chunk2URL.path }.map { $0.id }

        // Mix valid and invalid chunk IDs to simulate mid-transaction failure
        let mixedChunkIds = validChunkIds + [999999, 999998]

        let startTs = Int(Date().timeIntervalSince1970) + 5000
        let endTs = startTs + 900

        do {
            _ = try await storage.saveBatch(startTs: startTs, endTs: endTs, chunkIds: mixedChunkIds)
            XCTFail("Should throw error when some chunks don't exist")
        } catch {
            // Expected behavior - entire transaction should roll back

            // Verify 1: No batch was created
            let batches = try await storage.allBatches()
            let failedBatch = batches.first(where: { $0.start == startTs })
            XCTAssertNil(failedBatch, "Batch should not exist after rollback")

            // Verify 2: Valid chunks should remain unassociated (not linked to non-existent batch)
            // If transaction rolled back correctly, chunks should still be available for other batches
            let unprocessedChunks = try await storage.fetchUnprocessedChunks(olderThan: 0)
            let stillAvailable = unprocessedChunks.filter { validChunkIds.contains($0.id) }
            XCTAssertEqual(stillAvailable.count, validChunkIds.count,
                          "Valid chunks should remain unassociated after transaction rollback")
        }
    }

    // MARK: - AC-1.3.6: Performance <100ms P95

    func testDatabaseOperationLatency() async throws {
        // Measure latency of database operations to ensure P95 < 100ms
        var latencies: [TimeInterval] = []

        // Warm up
        for _ in 0..<5 {
            _ = try? await storage.fetchUnprocessedChunks(olderThan: 0)
        }

        // Measure 100 operations
        for i in 0..<100 {
            let start = Date()

            if i % 2 == 0 {
                // Read operation
                _ = try? await storage.fetchUnprocessedChunks(olderThan: 0)
            } else {
                // Write operation
                let url = URL(fileURLWithPath: "/tmp/perf-chunk-\(i).mp4")
                try? await storage.registerChunk(url: url)
            }

            let duration = Date().timeIntervalSince(start) * 1000 // Convert to ms
            latencies.append(duration)
        }

        // Calculate P95
        latencies.sort()
        let p95Index = Int(Double(latencies.count) * 0.95)
        let p95Latency = latencies[p95Index]

        print("Database operations P95 latency: \(p95Latency)ms")
        XCTAssertLessThan(p95Latency, 100.0, "P95 latency should be less than 100ms")
    }

    func testBatchOperationLatency() async throws {
        // Test batch operations latency
        var latencies: [TimeInterval] = []

        for i in 0..<50 {
            let start = Date()

            let startTs = Int(Date().timeIntervalSince1970) + (i * 1000)
            _ = try? await storage.saveBatch(startTs: startTs, endTs: startTs + 900, chunkIds: [])

            let duration = Date().timeIntervalSince(start) * 1000
            latencies.append(duration)
        }

        latencies.sort()
        let p95Index = Int(Double(latencies.count) * 0.95)
        let p95Latency = latencies[p95Index]

        print("Batch creation P95 latency: \(p95Latency)ms")
        XCTAssertLessThan(p95Latency, 100.0, "Batch creation P95 latency should be less than 100ms")
    }

    // MARK: - Additional Edge Cases

    func testMultipleTimelineCardFetches() async throws {
        // Test concurrent timeline card fetches don't cause threading issues
        await withTaskGroup(of: Void.self) { group in
            for i in 0..<20 {
                group.addTask {
                    _ = try? await self.storage.fetchTimelineCards(forDay: "2025-11-\(14 + (i % 7))")
                }
            }

            await group.waitForAll()
        }

        XCTAssert(true, "Concurrent timeline card fetches completed without crashes")
    }

    func testSendableConformance() {
        // Verify all data models conform to Sendable
        let chunk = RecordingChunk(id: 1, startTs: 0, endTs: 100, fileUrl: "/tmp/test.mp4", status: "completed")
        let card = TimelineCard(batchId: 1, startTimestamp: "9:00 AM", endTimestamp: "10:00 AM",
                               category: "Work", subcategory: "Coding", title: "Test", summary: "Test",
                               detailedSummary: "Test", day: "2025-11-14", distractions: nil,
                               videoSummaryURL: nil, otherVideoSummaryURLs: nil, appSites: nil)
        let llmCall = LLMCall(timestamp: Date(), latency: 1.0, input: "test", output: "test")

        // If this compiles, Sendable conformance is validated
        Task {
            _ = chunk
            _ = card
            _ = llmCall
        }

        XCTAssert(true, "All models conform to Sendable")
    }

    // MARK: - AC-1.3.6: Stress Test with 50+ Concurrent Operations

    func testStressTestFiftyPlusConcurrentOperations() async throws {
        // AC-1.3.6 requirement: 50 concurrent AI analysis + UI interactions
        // This test simulates realistic production load with sustained concurrent access

        let testStartTime = Date()
        var operationCount = 0
        let operationCountLock = NSLock()

        // Setup: Create some initial test data for UI fetches
        let setupBatchId = try await storage.saveBatch(
            startTs: Int(Date().timeIntervalSince1970),
            endTs: Int(Date().timeIntervalSince1970) + 900,
            chunkIds: []
        )
        XCTAssertNotNil(setupBatchId)

        await withTaskGroup(of: Void.self) { group in
            // Simulate 25 concurrent AI batch processing operations
            // Realistic AI workflow: create batch, update status, save timeline cards
            for i in 0..<25 {
                group.addTask {
                    do {
                        let startTs = Int(Date().timeIntervalSince1970) + (i * 1000)
                        let endTs = startTs + 900

                        // Step 1: Create AI analysis batch
                        let batchId = try await self.storage.saveBatch(
                            startTs: startTs,
                            endTs: endTs,
                            chunkIds: []
                        )

                        guard let batchId = batchId else { return }

                        // Step 2: Update batch status (simulating AI processing)
                        try await self.storage.updateBatchStatus(batchId: batchId, status: "processing")

                        // Step 3: Save timeline card (simulating AI results)
                        let card = TimelineCardShell(
                            startTimestamp: "10:00 AM",
                            endTimestamp: "10:15 AM",
                            category: "Work",
                            subcategory: "Coding",
                            title: "AI Analysis \(i)",
                            summary: "Test summary",
                            detailedSummary: "Test detailed summary",
                            day: "2025-11-14",
                            distractions: nil,
                            appSites: nil
                        )
                        try await self.storage.saveTimelineCardShell(batchId: batchId, card: card)

                        // Step 4: Mark batch complete
                        try await self.storage.updateBatchStatus(batchId: batchId, status: "completed")

                        operationCountLock.lock()
                        operationCount += 1
                        operationCountLock.unlock()
                    } catch {
                        print("AI batch processing error: \(error)")
                    }
                }
            }

            // Simulate 25 concurrent UI timeline fetch operations
            // Realistic UI workflow: fetch timeline cards for display
            for i in 0..<25 {
                group.addTask {
                    do {
                        // Mix of different fetch operations
                        if i % 3 == 0 {
                            // Fetch by day (common UI operation)
                            _ = try await self.storage.fetchTimelineCards(forDay: "2025-11-14")
                        } else if i % 3 == 1 {
                            // Fetch by batch (details view)
                            if let setupBatchId = setupBatchId {
                                _ = try await self.storage.fetchTimelineCards(forBatch: setupBatchId)
                            }
                        } else {
                            // Fetch by time range (scrolling timeline)
                            let from = Date().addingTimeInterval(-3600)
                            let to = Date()
                            _ = try await self.storage.fetchTimelineCardsByTimeRange(from: from, to: to)
                        }

                        operationCountLock.lock()
                        operationCount += 1
                        operationCountLock.unlock()
                    } catch {
                        print("UI timeline fetch error: \(error)")
                    }
                }
            }

            // Wait for all 50 operations to complete
            await group.waitForAll()
        }

        let testDuration = Date().timeIntervalSince(testStartTime)

        // Validate stress test results
        XCTAssertGreaterThanOrEqual(operationCount, 45, "At least 45 of 50 operations should complete successfully (90% success rate)")
        XCTAssertGreaterThanOrEqual(testDuration, 0.1, "Stress test should run for measurable duration to validate sustained load")

        print("âœ… Stress test completed: \(operationCount)/50 operations successful in \(String(format: "%.2f", testDuration))s")
        print("   Average throughput: \(String(format: "%.1f", Double(operationCount) / testDuration)) ops/sec")
    }
}
